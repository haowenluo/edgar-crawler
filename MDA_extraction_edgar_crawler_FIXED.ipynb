{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIXED: MD&A EXTRACTION WITH YEAR SUBFOLDER ORGANIZATION\n",
    "\n",
    "**Purpose:** Extract MD&A sections from 10-K filings with Drive timeout fix\n",
    "\n",
    "**CRITICAL FIX:** Reorganizes files into year subfolders to avoid Google Drive's ~10,000 file limit\n",
    "\n",
    "**TWO FIX STRATEGIES:**\n",
    "- **Strategy 1:** Try waiting 3-4 hours, then run standard reorganization\n",
    "- **Strategy 2:** Progressive reorganization (moves files during extraction, one-by-one)\n",
    "\n",
    "**Prerequisites:**\n",
    "- Repository: `/content/drive/MyDrive/EDGAR_Project/edgar-crawler`\n",
    "- Raw 10-K files downloaded\n",
    "- **~75,000 extracted files causing Drive timeouts**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECTION 1: SETUP (Run Every Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## üü¢ Cell 1: Mount Google Drive\n",
    "import os\n",
    "from google.colab import drive\n",
    "\n",
    "if os.path.exists('/content/drive/MyDrive'):\n",
    "    print(\"‚úÖ Drive already mounted\")\n",
    "else:\n",
    "    drive.mount('/content/drive')\n",
    "    print(\"‚úÖ Drive mounted successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## üü¢ Cell 2: Navigate to Repository\n",
    "import os\n",
    "\n",
    "REPO_DIR = '/content/drive/MyDrive/EDGAR_Project/edgar-crawler'\n",
    "\n",
    "if os.path.exists(REPO_DIR):\n",
    "    os.chdir(REPO_DIR)\n",
    "    print(f\"‚úÖ Working directory: {os.getcwd()}\")\n",
    "else:\n",
    "    print(f\"‚ùå Repository not found at: {REPO_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## üü¢ Cell 3: Install Dependencies\n",
    "print(\"üì¶ Installing dependencies...\")\n",
    "\n",
    "!pip install -q 'dill<0.3.9' 'multiprocess<0.70.17'\n",
    "!pip install -q pox ppft\n",
    "!pip install -q --no-deps pathos\n",
    "!pip install -q beautifulsoup4 lxml requests pandas tqdm click cssutils numpy pyarrow\n",
    "\n",
    "print(\"‚úÖ All dependencies installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## üü¢ Cell 4: Keep-Alive Script\n",
    "from IPython.display import display, Javascript\n",
    "\n",
    "display(Javascript('''\n",
    "function KeepClicking(){\n",
    "    console.log(\"Keeping session alive...\");\n",
    "    document.querySelector(\"colab-connect-button\").click();\n",
    "}\n",
    "setInterval(KeepClicking, 60000);\n",
    "'''))\n",
    "\n",
    "print(\"‚úÖ Keep-alive activated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STRATEGY 1: Wait & Retry Standard Reorganization\n",
    "\n",
    "**üü° TRY THIS FIRST!**\n",
    "\n",
    "If you got `[Errno 5] Input/output error` when listing directory:\n",
    "1. **Wait 3-4 hours** (don't access the folder)\n",
    "2. **Restart Colab runtime** (Runtime ‚Üí Restart runtime)\n",
    "3. **Re-run Cells 1-4** (setup)\n",
    "4. **Try reorganization below**\n",
    "\n",
    "Drive's cache/locks often clear after a few hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## üî¥ STRATEGY 1: Standard Reorganization (Try After Waiting)\n",
    "## \n",
    "## What it does:\n",
    "## - Lists all files in root directory\n",
    "## - Groups by year\n",
    "## - Moves to year subfolders\n",
    "##\n",
    "## If this fails with [Errno 5], use Strategy 2 below!\n",
    "\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "print(\"üîß STRATEGY 1: STANDARD REORGANIZATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "base_dir = 'datasets/EXTRACTED_FILINGS/10-K'\n",
    "\n",
    "if not os.path.exists(base_dir):\n",
    "    print(f\"‚ùå Directory not found: {base_dir}\")\n",
    "else:\n",
    "    print(\"üìä Attempting to list directory...\")\n",
    "    \n",
    "    try:\n",
    "        all_items = os.listdir(base_dir)\n",
    "        root_files = [f for f in all_items if os.path.isfile(os.path.join(base_dir, f)) and f.endswith('.json')]\n",
    "        print(f\"‚úÖ Success! Found {len(root_files):,} files to reorganize\\n\")\n",
    "        \n",
    "        if len(root_files) == 0:\n",
    "            print(\"‚úÖ No files to reorganize - already organized!\")\n",
    "        else:\n",
    "            # Group by year\n",
    "            print(\"üìä Grouping by year...\")\n",
    "            year_pattern = re.compile(r'_10K_(\\d{4})_')\n",
    "            year_groups = {}\n",
    "            \n",
    "            for filename in root_files:\n",
    "                match = year_pattern.search(filename)\n",
    "                if match:\n",
    "                    year = match.group(1)\n",
    "                    if year not in year_groups:\n",
    "                        year_groups[year] = []\n",
    "                    year_groups[year].append(filename)\n",
    "            \n",
    "            for year in sorted(year_groups.keys()):\n",
    "                print(f\"   {year}: {len(year_groups[year]):,} files\")\n",
    "            \n",
    "            # Move files\n",
    "            print(f\"\\nüöÄ Moving files to year subfolders...\\n\")\n",
    "            \n",
    "            moved_count = 0\n",
    "            for year in sorted(year_groups.keys()):\n",
    "                year_dir = os.path.join(base_dir, year)\n",
    "                os.makedirs(year_dir, exist_ok=True)\n",
    "                \n",
    "                for filename in tqdm(year_groups[year], desc=f\"Year {year}\", leave=False):\n",
    "                    try:\n",
    "                        src = os.path.join(base_dir, filename)\n",
    "                        dst = os.path.join(year_dir, filename)\n",
    "                        os.rename(src, dst)\n",
    "                        moved_count += 1\n",
    "                        \n",
    "                        if moved_count % 100 == 0:\n",
    "                            time.sleep(0.5)\n",
    "                    except Exception as e:\n",
    "                        print(f\"\\n‚ö†Ô∏è Error moving {filename}: {e}\")\n",
    "            \n",
    "            print(f\"\\n‚úÖ REORGANIZATION COMPLETE!\")\n",
    "            print(f\"   Moved: {moved_count:,} files\")\n",
    "            print(f\"\\nüéâ Now run the patch script below, then resume extraction!\")\n",
    "            \n",
    "    except OSError as e:\n",
    "        print(f\"‚ùå FAILED: {e}\")\n",
    "        print(f\"\\n\" + \"=\" * 60)\n",
    "        print(\"‚ö†Ô∏è  Directory listing failed!\")\n",
    "        print(\"   This means Drive is blocking access to the folder.\")\n",
    "        print(\"\\n   ‚Üí Use STRATEGY 2 (Progressive Reorganization) below\")\n",
    "        print(\"   ‚Üí It moves files one-by-one during extraction\")\n",
    "        print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STRATEGY 2: Progressive Reorganization (USE IF STRATEGY 1 FAILS)\n",
    "\n",
    "**üü† USE THIS IF DIRECTORY LISTING FAILS**\n",
    "\n",
    "**How it works:**\n",
    "- Doesn't try to list all 75,000 files at once\n",
    "- Checks files one-by-one using metadata\n",
    "- Moves old files AND extracts new files during extraction\n",
    "- Works even when `os.listdir()` fails!\n",
    "\n",
    "**What happens:**\n",
    "- ~75,000 existing files: Moved to year folders\n",
    "- ~8,000 remaining files: Extracted to year folders\n",
    "- Total time: Same as normal extraction (~10-15 hours)\n",
    "\n",
    "**Run cells below in order:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## üü† STRATEGY 2 - Step 1: Apply Progressive Reorganization Patch\n##\n## This patches extract_items.py to:\n## 1. Check if file exists in OLD location (root)\n## 2. If yes: MOVE it to year folder, mark as done\n## 3. If no: Check if in NEW location (year folder)\n## 4. If no: Extract to NEW location\n\nprint(\"üîß Applying progressive reorganization patch...\\n\")\n\n!python progressive_reorganization_patch.py"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## üü† STRATEGY 2 - Step 2: Test Progressive Reorganization\n",
    "##\n",
    "## This tests if individual file access works (even when listing fails)\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "print(\"üß™ Testing progressive access...\\n\")\n",
    "\n",
    "base_dir = 'datasets/EXTRACTED_FILINGS/10-K'\n",
    "\n",
    "# Load metadata\n",
    "metadata = pd.read_csv('datasets/FILINGS_METADATA.csv')\n",
    "metadata_10k = metadata[metadata['Type'] == '10-K']\n",
    "\n",
    "print(f\"üìä Total files in metadata: {len(metadata_10k):,}\")\n",
    "\n",
    "# Test: Can we check individual files?\n",
    "print(f\"\\nüß™ Testing individual file access (first 10 files):\\n\")\n",
    "\n",
    "test_count = 0\n",
    "found_in_root = 0\n",
    "found_in_subfolder = 0\n",
    "not_found = 0\n",
    "\n",
    "for idx, row in metadata_10k.head(10).iterrows():\n",
    "    # Generate expected filename\n",
    "    cik = str(row['CIK'])\n",
    "    year = row['year']\n",
    "    accession = row['accession_number']\n",
    "    filename = f\"{cik}_10K_{year}_{accession}.json\"\n",
    "    \n",
    "    # Check old location (root)\n",
    "    old_path = os.path.join(base_dir, filename)\n",
    "    # Check new location (year subfolder)\n",
    "    new_path = os.path.join(base_dir, str(year), filename)\n",
    "    \n",
    "    if os.path.exists(old_path):\n",
    "        found_in_root += 1\n",
    "        status = \"üìÅ Root (will move)\"\n",
    "    elif os.path.exists(new_path):\n",
    "        found_in_subfolder += 1\n",
    "        status = f\"üìÇ {year}/ (organized)\"\n",
    "    else:\n",
    "        not_found += 1\n",
    "        status = \"‚ùå Not extracted\"\n",
    "    \n",
    "    print(f\"   {filename[:50]:50s} {status}\")\n",
    "    test_count += 1\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(f\"‚úÖ Individual file access: WORKS!\")\n",
    "print(f\"   Tested: {test_count} files\")\n",
    "print(f\"   In root: {found_in_root}\")\n",
    "print(f\"   In year folders: {found_in_subfolder}\")\n",
    "print(f\"   Not extracted: {not_found}\")\n",
    "print(f\"\\nüéâ Progressive reorganization will work!\")\n",
    "print(f\"   Run extraction below to start moving + extracting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESUME EXTRACTION\n",
    "\n",
    "**Run this after:**\n",
    "- Strategy 1 successful reorganization, OR\n",
    "- Strategy 2 progressive reorganization patch applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## üü¢ Resume MD&A Extraction\n",
    "##\n",
    "## With Strategy 1: Files already organized, extracts remaining files\n",
    "## With Strategy 2: Moves old files + extracts new files during extraction\n",
    "\n",
    "print(\"üöÄ Resuming MD&A extraction...\")\n",
    "print(\"   Files will be organized by year\")\n",
    "print(\"   Should avoid Drive timeout issues\\n\")\n",
    "\n",
    "!python flexible_extractor.py --config extraction_configs/mda_only.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHECK PROGRESS (Works with Both Strategies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## üîµ Check Extraction Progress (UPDATED FOR YEAR SUBFOLDERS)\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "extracted_dir = 'datasets/EXTRACTED_FILINGS/10-K'\n",
    "\n",
    "if os.path.exists(extracted_dir):\n",
    "    print(\"üìä Scanning for extracted files (including year subfolders)...\\n\")\n",
    "    \n",
    "    # Count all JSON files recursively\n",
    "    all_files = []\n",
    "    year_counts = {}\n",
    "    root_count = 0\n",
    "    \n",
    "    try:\n",
    "        for root, dirs, files in os.walk(extracted_dir):\n",
    "            json_files = [f for f in files if f.endswith('.json')]\n",
    "            all_files.extend([os.path.join(root, f) for f in json_files])\n",
    "            \n",
    "            if root == extracted_dir:\n",
    "                root_count = len(json_files)\n",
    "            else:\n",
    "                year = os.path.basename(root)\n",
    "                year_counts[year] = len(json_files)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error scanning: {e}\")\n",
    "    \n",
    "    # Get expected total\n",
    "    metadata = pd.read_csv('datasets/FILINGS_METADATA.csv')\n",
    "    expected = len(metadata[metadata['Type'] == '10-K'])\n",
    "    \n",
    "    print(f\"üìä Extraction Progress:\")\n",
    "    print(f\"   Total Extracted: {len(all_files):,} files\")\n",
    "    print(f\"   Expected: {expected:,} files\")\n",
    "    print(f\"   Progress: {len(all_files)/expected*100:.1f}%\")\n",
    "    print(f\"   Remaining: {expected - len(all_files):,} files\")\n",
    "    \n",
    "    # Show organization\n",
    "    if year_counts or root_count > 0:\n",
    "        print(f\"\\nüìÅ File organization:\")\n",
    "        \n",
    "        if root_count > 0:\n",
    "            print(f\"   Root (not organized): {root_count:,} files\")\n",
    "            if root_count > 10000:\n",
    "                print(f\"      ‚ö†Ô∏è WARNING: Too many files in root!\")\n",
    "                print(f\"      Drive may timeout again\")\n",
    "            else:\n",
    "                print(f\"      ‚úÖ Acceptable (will be moved progressively)\")\n",
    "        \n",
    "        if year_counts:\n",
    "            print(f\"   Year subfolders: {sum(year_counts.values()):,} files\")\n",
    "            for year in sorted(year_counts.keys()):\n",
    "                print(f\"      {year}/: {year_counts[year]:,} files\")\n",
    "    \n",
    "    # Sample quality check\n",
    "    if len(all_files) > 0:\n",
    "        print(f\"\\nüìã Sample Quality Check (3 random files):\")\n",
    "        import random\n",
    "        sample = random.sample(all_files, min(3, len(all_files)))\n",
    "        \n",
    "        for fpath in sample:\n",
    "            fname = os.path.basename(fpath)\n",
    "            try:\n",
    "                with open(fpath, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                    has_mda = 'item_7' in data and len(data.get('item_7', '')) > 100\n",
    "                    mda_len = len(data.get('item_7', ''))\n",
    "                    print(f\"   {fname}: {'‚úÖ' if has_mda else '‚ùå'} MD&A ({mda_len:,} chars)\")\n",
    "            except Exception as e:\n",
    "                print(f\"   {fname}: ‚ö†Ô∏è Error - {e}\")\n",
    "                \n",
    "else:\n",
    "    print(\"‚ùå No extraction directory found\")\n",
    "    print(f\"   Expected: {extracted_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}